{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim \n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training and Testing Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images, training_labels = tfds.as_numpy(tfds.load(\n",
    "                                        'mnist',\n",
    "                                        split='train', \n",
    "                                        batch_size=-1, \n",
    "                                        as_supervised=True,\n",
    "                                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_images, testing_labels = tfds.as_numpy(tfds.load(\n",
    "                                        'mnist',\n",
    "                                        split='test', \n",
    "                                        batch_size=-1, \n",
    "                                        as_supervised=True,\n",
    "                                    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train Simple Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                nn.Conv1d(1,10,kernel_size=(3,3)),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(10,100,kernel_size=(3,3)),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(57600,10),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainNetwork(model,device,training_loader,testing_loader,numIter):\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer     = optim.Adam(model.parameters())\n",
    "\n",
    "    loss_array     = np.zeros([numIter,2])\n",
    "    accuracy_array = np.zeros([numIter,2])\n",
    "\n",
    "    for epoch in range(numIter):\n",
    "\n",
    "        training_loss_array = []\n",
    "        testing_loss_array  = []\n",
    "\n",
    "        training_correct = 0\n",
    "        testing_correct  = 0\n",
    "\n",
    "        for image_batch, label_batch in training_loader:\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output            = model(image_batch.to(device))\n",
    "            \n",
    "            training_loss = loss_function(output,label_batch.to(device))\n",
    "            \n",
    "            training_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss_array.append(training_loss.cpu().item())\n",
    "            \n",
    "            _, predicted      = torch.max(output.data, 1)\n",
    "            training_correct += (predicted.cpu() == label_batch).sum().item()\n",
    "            \n",
    "        for image_batch, label_batch in testing_loader:\n",
    "\n",
    "            model.eval()\n",
    "            \n",
    "            output            = model(image_batch.to(device))\n",
    "            \n",
    "            testing_loss = loss_function(model(image_batch.to(device)),label_batch.to(device))\n",
    "            \n",
    "            testing_loss_array.append(testing_loss.cpu().item())\n",
    "\n",
    "            _, predicted     = torch.max(output.data, 1)\n",
    "            testing_correct += (predicted.cpu() == label_batch).sum().item()\n",
    "            \n",
    "        print('Epoch: ' + str(epoch))\n",
    "        print()\n",
    "        print(\"Training Loss: \" + '\\t\\t' + str(np.mean(training_loss_array)))\n",
    "        print(\"Testing Loss: \" + '\\t\\t' + str(np.mean(testing_loss_array)))\n",
    "        print(\"Training Accuracy: \" + '\\t' + str(100.0*training_correct/len(training_labels)) + '%')\n",
    "        print(\"Testing Accuracy: \" + '\\t' + str(100.0*testing_correct/len(testing_labels)) + '%')\n",
    "\n",
    "        loss_array[epoch,0] = np.mean(training_loss_array)\n",
    "        loss_array[epoch,1] = np.mean(testing_loss_array)\n",
    "        \n",
    "        accuracy_array[epoch,0] = np.mean(100.0*training_correct/len(training_labels))\n",
    "        accuracy_array[epoch,1] = np.mean(100.0*testing_correct/len(testing_labels))\n",
    "        \n",
    "        print()\n",
    "        \n",
    "    return loss_array, accuracy_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros([10,10])\n",
    "\n",
    "for ii in range(10):\n",
    "    \n",
    "    labels[ii,ii] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_pytorch = torch.Tensor(training_images).transpose(1,3)\n",
    "training_labels_pytorch = torch.Tensor(training_labels).type(torch.LongTensor)\n",
    "\n",
    "testing_images_pytorch = torch.Tensor(testing_images).transpose(1,3)\n",
    "testing_labels_pytorch = torch.Tensor(testing_labels).type(torch.LongTensor)\n",
    "\n",
    "training_dataset = TensorDataset(training_images_pytorch,training_labels_pytorch)\n",
    "testing_dataset  = TensorDataset(testing_images_pytorch,testing_labels_pytorch)\n",
    "\n",
    "training_loader = DataLoader(training_dataset, batch_size=5, shuffle=True, pin_memory=True,drop_last=True)\n",
    "testing_loader  = DataLoader(testing_dataset, batch_size=5, shuffle=True, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_array, accuracy_array = TrainNetwork(model,device,training_loader,testing_loader,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Detection using Filtering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lambda(labels,label_vals):\n",
    "    \n",
    "    lambda_vals = np.zeros([len(label_vals)])\n",
    "    \n",
    "    for val in range(len(label_vals)):\n",
    "        \n",
    "        lambda_vals[val] = (val == labels).sum().item()/len(labels)\n",
    "        \n",
    "    return lambda_vals\n",
    "\n",
    "def LambdaPredictionTransition(x,lambda_vals):\n",
    "    \n",
    "    x = x + lambda_vals\n",
    "    return x\n",
    "\n",
    "def LambdaFilterTransition(x,y):\n",
    "    \n",
    "    x = x + 0.01*(y-x)\n",
    "    return x\n",
    "\n",
    "def LambdaObservataion(y,label_pred):\n",
    "    \n",
    "    lambda_vals = calculate_lambda(label_pred,torch.Tensor(np.arange(0,10)).int())\n",
    "    y = y + lambda_vals\n",
    "    return y\n",
    "    \n",
    "def Residual(x,y):\n",
    "    \n",
    "    r = np.linalg.norm(x-y)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data set manipulation for detection tests\n",
    "\n",
    "Here we remove half of the examples of the MNIST data set that are labeled as number 0. We are to test if there is a shift in the distribution of the detection signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples     = len(np.where(testing_labels>0)[0])+int(len(np.where(testing_labels==0)[0])/2)\n",
    "detection_images = torch.zeros([num_examples,1,28,28])\n",
    "detection_labels = torch.zeros([num_examples])\n",
    "\n",
    "image_ids        = np.where(testing_labels>0)\n",
    "rand_id          = np.random.randint(len(image_ids[0]),size=[int(len(image_ids[0]))])\n",
    "\n",
    "detection_images[0:len(np.where(testing_labels>0)[0]),:,:,:] = testing_images_pytorch[image_ids[0][rand_id],:,:,:]\n",
    "detection_labels[0:len(np.where(testing_labels>0)[0])]       = testing_labels_pytorch[image_ids[0][rand_id]]\n",
    "\n",
    "image_ids        = np.where(testing_labels==0)\n",
    "rand_id          = np.random.randint(len(image_ids[0]),size=[int(len(image_ids[0])/2)])\n",
    "\n",
    "detection_images[len(np.where(testing_labels>0)[0]):,:,:,:] = testing_images_pytorch[image_ids[0][rand_id],:,:,:]\n",
    "detection_labels[len(np.where(testing_labels>0)[0]):]       = testing_labels_pytorch[image_ids[0][rand_id]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_vals_training  = calculate_lambda(training_labels_pytorch,torch.Tensor(np.arange(0,10)).int())\n",
    "lambda_vals_testing   = calculate_lambda(testing_labels_pytorch,torch.Tensor(np.arange(0,10)).int())\n",
    "lambda_vals_detection = calculate_lambda(detection_labels,torch.Tensor(np.arange(0,10)).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of batch size on detection\n",
    "\n",
    "Here we increase the batch size to see how this affects the detection variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_dataset = TensorDataset(detection_images,detection_labels)\n",
    "\n",
    "no_shift_detection_loader  = DataLoader(testing_dataset, batch_size=1, shuffle=True, pin_memory=True,drop_last=True)\n",
    "shift_detection_loader     = DataLoader(detection_dataset, batch_size=1, shuffle=True, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "\n",
    "x = np.zeros([len(lambda_vals_training),len(no_shift_detection_loader)])\n",
    "y = np.zeros([len(lambda_vals_training),len(no_shift_detection_loader)])\n",
    "r = np.zeros([len(no_shift_detection_loader)])\n",
    "\n",
    "for image_batch, label_batch in no_shift_detection_loader:\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output           = model(image_batch.to(device))\n",
    "\n",
    "    _, predicted     = torch.max(output.data, 1)\n",
    "    \n",
    "    x[:,k+1] = LambdaPredictionTransition(x[:,k],lambda_vals_training)\n",
    "    y[:,k+1] = LambdaObservataion(y[:,k],predicted)\n",
    "    r[k]     = Residual(x[:,k+1],y[:,k+1])\n",
    "    x[:,k+1] = LambdaFilterTransition(x[:,k+1],y[:,k+1])\n",
    "\n",
    "    k += 1\n",
    "    \n",
    "    if k+1 == len(no_shift_detection_loader):\n",
    "        break\n",
    "\n",
    "r_test = r\n",
    "\n",
    "k = 0\n",
    "\n",
    "x = np.zeros([len(lambda_vals_training),len(shift_detection_loader)])\n",
    "y = np.zeros([len(lambda_vals_training),len(shift_detection_loader)])\n",
    "r = np.zeros([len(shift_detection_loader)])\n",
    "\n",
    "for image_batch, label_batch in shift_detection_loader:\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output           = model(image_batch.to(device))\n",
    "\n",
    "    _, predicted     = torch.max(output.data, 1)\n",
    "    \n",
    "    x[:,k+1] = LambdaPredictionTransition(x[:,k],lambda_vals_training)\n",
    "    y[:,k+1] = LambdaObservataion(y[:,k],predicted)\n",
    "    r[k]     = Residual(x[:,k+1],y[:,k+1])\n",
    "    x[:,k+1] = LambdaFilterTransition(x[:,k+1],y[:,k+1])\n",
    "\n",
    "    k += 1\n",
    "    \n",
    "    if k+1 == len(shift_detection_loader):\n",
    "        break\n",
    "\n",
    "r_detect = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_up,   = plt.plot(r_test, label='No Label Shift')\n",
    "line_down, = plt.plot(r_detect, label='Label Shift')\n",
    "plt.legend(handles=[line_up, line_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,14,100)\n",
    "\n",
    "hist_no_shift, _ = np.histogram(r_test, bins=bins, density=True)\n",
    "hist_shift, _    = np.histogram(r_detect, bins=bins, density=True)\n",
    "\n",
    "line_up,   = plt.plot(bins[0:99],hist_no_shift, label='No Label Shift')\n",
    "line_down, = plt.plot(bins[0:99],hist_shift, label='Label Shift')\n",
    "\n",
    "plt.legend(handles=[line_up, line_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_dataset = TensorDataset(detection_images,detection_labels)\n",
    "\n",
    "no_shift_detection_loader  = DataLoader(testing_dataset, batch_size=5, shuffle=True, pin_memory=True,drop_last=True)\n",
    "shift_detection_loader     = DataLoader(detection_dataset, batch_size=5, shuffle=True, pin_memory=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "\n",
    "x = np.zeros([len(lambda_vals_training),len(no_shift_detection_loader)])\n",
    "y = np.zeros([len(lambda_vals_training),len(no_shift_detection_loader)])\n",
    "r = np.zeros([len(no_shift_detection_loader)])\n",
    "\n",
    "for image_batch, label_batch in no_shift_detection_loader:\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output           = model(image_batch.to(device))\n",
    "\n",
    "    _, predicted     = torch.max(output.data, 1)\n",
    "    \n",
    "    x[:,k+1] = LambdaPredictionTransition(x[:,k],lambda_vals_training)\n",
    "    y[:,k+1] = LambdaObservataion(y[:,k],predicted)\n",
    "    r[k]     = Residual(x[:,k+1],y[:,k+1])\n",
    "    x[:,k+1] = LambdaFilterTransition(x[:,k+1],y[:,k+1])\n",
    "\n",
    "    k += 1\n",
    "    \n",
    "    if k+1 == len(no_shift_detection_loader):\n",
    "        break\n",
    "\n",
    "r_test = r\n",
    "\n",
    "k = 0\n",
    "\n",
    "x = np.zeros([len(lambda_vals_training),len(shift_detection_loader)])\n",
    "y = np.zeros([len(lambda_vals_training),len(shift_detection_loader)])\n",
    "r = np.zeros([len(shift_detection_loader)])\n",
    "\n",
    "for image_batch, label_batch in shift_detection_loader:\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    output           = model(image_batch.to(device))\n",
    "\n",
    "    _, predicted     = torch.max(output.data, 1)\n",
    "    \n",
    "    x[:,k+1] = LambdaPredictionTransition(x[:,k],lambda_vals_training)\n",
    "    y[:,k+1] = LambdaObservataion(y[:,k],predicted)\n",
    "    r[k]     = Residual(x[:,k+1],y[:,k+1])\n",
    "    x[:,k+1] = LambdaFilterTransition(x[:,k+1],y[:,k+1])\n",
    "\n",
    "    k += 1\n",
    "    \n",
    "    if k+1 == len(shift_detection_loader):\n",
    "        break\n",
    "\n",
    "r_detect = r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_up,   = plt.plot(r_test, label='No Label Shift')\n",
    "line_down, = plt.plot(r_detect, label='Label Shift')\n",
    "plt.legend(handles=[line_up, line_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0,14,100)\n",
    "\n",
    "hist_no_shift, _ = np.histogram(r_test, bins=bins, density=True)\n",
    "hist_shift, _    = np.histogram(r_detect, bins=bins, density=True)\n",
    "\n",
    "line_up,   = plt.plot(bins[0:99],hist_no_shift, label='No Label Shift')\n",
    "line_down, = plt.plot(bins[0:99],hist_shift, label='Label Shift')\n",
    "\n",
    "plt.legend(handles=[line_up, line_down])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
